# diffusion-research
research for diffusion model

## Scheduler
- [On the Importance of Noise Scheduling for Diffusion Models](https://arxiv.org/abs/2301.10972)  
**TL; DR**: same noise level will have different influence on different resolution.
- [Common Diffusion Noise Schedules and Sample Steps are Flawed](https://arxiv.org/abs/2305.08891)  
**TL; DR**: terminal snr is not zero so information leak.
- [Perception Prioritized Training of Diffusion Models](https://arxiv.org/abs/2204.00227)

## Parameter-Efficient Fine-Tuning
- [LoRA: Low-Rank Adaptation of Large Language Models](https://arxiv.org/abs/2106.09685)
- [Controlling Text-to-Image Diffusion by Orthogonal Finetuning](https://arxiv.org/abs/2306.07280)
- [DoRA: Weight-Decomposed Low-Rank Adaptation](https://arxiv.org/abs/2402.09353)
- [LoRA+: Efficient Low Rank Adaptation of Large Models](https://arxiv.org/abs/2402.12354)

## Personalization
- [DreamBooth: Fine Tuning Text-to-Image Diffusion Models for Subject-Driven Generation](https://arxiv.org/abs/2208.12242v2)

## Controlable
- [Adding Conditional Control to Text-to-Image Diffusion Models](https://arxiv.org/abs/2302.05543)

## Architecture
- [Scalable Diffusion Models with Transformers](https://arxiv.org/abs/2212.09748)  
**TL; DR**: aka DiT

## Acceleration
- [Latent Consistency Models: Synthesizing High-Resolution Images with Few-Step Inference](https://arxiv.org/abs/2310.04378)
- [Adversarial Diffusion Distillation](https://arxiv.org/abs/2311.17042)
- [SDXL-Lightning: Progressive Adversarial Diffusion Distillation](https://arxiv.org/abs/2402.13929)


## Application

## Repo
- [PhilSad/stable-diffusion-outpainting](https://github.com/PhilSad/stable-diffusion-outpainting)
- [HighCWu/control-lora-v2](https://github.com/HighCWu/control-lora-v2)
